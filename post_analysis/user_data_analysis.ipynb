{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all user data\n",
    "df = pd.read_csv('./../freetext/FreeText-Dataset-31-USERS.csv')\n",
    "\n",
    "# data as array\n",
    "user_data = [df.loc[df['user'] == i] for i in range(1, 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all user data\n",
    "# compare to [13, 18, 26]\n",
    "for (i, x) in enumerate(user_data):\n",
    "    if i in [13, 18, 26]:\n",
    "        print(i, \"user: \", i+1)\n",
    "        timestamp = np.array(x['timestamp'])\n",
    "\n",
    "        plt.xlabel('Number of Inputs')\n",
    "        plt.ylabel('Time')\n",
    "        plt.plot(np.arange(0, len(timestamp)), timestamp)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse user profiles\n",
    "# dict_keys(['digraphs', 'trigraphs', 'fourgraphs'])\n",
    "\n",
    "\n",
    "# n-grpahs for all users(0-31) for all sets(0-15) \n",
    "digraphs = []\n",
    "trigraphs = []\n",
    "fourgraphs = []\n",
    "\n",
    "with open(\"./../freetext/__DATA/original_data_profiles\", \"rb\") as fp:\n",
    "    user_profiles = pickle.load(fp)\n",
    "\n",
    "    # extrace n-graphs into lists\n",
    "    digraphs = [userdata['digraphs'] for userdata in user_profiles]\n",
    "    trigraphs = [userdata['trigraphs'] for userdata in user_profiles]\n",
    "    fourgraphs =  [userdata['fourgraphs'] for userdata in user_profiles]\n",
    "\n",
    "\n",
    "def compact_data(ngraphs:list[list[dict]]) -> list[dict]:\n",
    "    '''\n",
    "    Compacts data from all user profiles into key indicators.\n",
    "    '''\n",
    "\n",
    "    dicts = []\n",
    "\n",
    "    # visualize n-graphs\n",
    "    for user in range(0, 31):\n",
    "\n",
    "        # create dict containing lists for each n-graph from each set\n",
    "        dict = {}\n",
    "\n",
    "        # from each set, add n-graph data\n",
    "        for set in range(0, 15):\n",
    "            # get all n-graph combinations\n",
    "            keys = list(ngraphs[user][set].keys())\n",
    "            # insert each n-graph from this set into dict\n",
    "            for key in keys:\n",
    "                # if this is a new n-graph, add a list, \n",
    "                if dict.get(key) is None:\n",
    "                    dict[key] = []\n",
    "\n",
    "                # then append to list\n",
    "                dict[key].append(ngraphs[user][set][key])\n",
    "\n",
    "        # compact n-graph data\n",
    "        for key in dict:\n",
    "            # get n-graph data\n",
    "            ngraph_data = np.array(dict[key])\n",
    "            # calculate key values\n",
    "            mean = ngraph_data.mean()\n",
    "            std = ngraph_data.std()\n",
    "            median = np.median(ngraph_data)\n",
    "            l = len(ngraph_data)\n",
    "\n",
    "            # update dict to contain only key data\n",
    "            dict[key] = {\n",
    "                \"mean\": mean, \n",
    "                \"median\": median,\n",
    "                \"std\": std,\n",
    "                \"len\": l\n",
    "            }\n",
    "        \n",
    "        # append user dict to list\n",
    "        dicts.append(dict)\n",
    "    \n",
    "    return dicts\n",
    "\n",
    "\n",
    "compact_digraphs = compact_data(digraphs)\n",
    "compact_trigraphs = compact_data(trigraphs)\n",
    "compact_fourgraphs = compact_data(fourgraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try visualize\n",
    "\n",
    "def visualize(ngraphs_compact:list[list[dict]], all: bool):\n",
    "\n",
    "    for (user, data) in enumerate(ngraphs_compact):\n",
    "\n",
    "\n",
    "        if user in [13, 18, 26] or all:\n",
    "            figure, axis = plt.subplots(3)\n",
    "            print(\"found\")\n",
    "            \n",
    "\n",
    "\n",
    "            keys = list(data.keys())\n",
    "            means = [data[k]['mean'] for k in keys]\n",
    "            meadians = [data[k]['median'] for k in keys]\n",
    "            stds = [data[k]['std'] for k in keys]\n",
    "\n",
    "            print(\"user index: \", user)\n",
    "\n",
    "            axis[0].set_title(\"Means\")\n",
    "            axis[0].bar(range(len(means)), means)\n",
    "\n",
    "            axis[1].set_title(\"Medians\")\n",
    "            axis[1].bar(range(len(meadians)), meadians)\n",
    "\n",
    "            axis[2].set_title(\"Stds\")\n",
    "            axis[2].bar(range(len(stds)), stds)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "#visualize(compact_digraphs, False)\n",
    "#visualize(compact_data(trigraphs), False)\n",
    "#visualize(compact_data(fourgraphs), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average / export\n",
    "def average(ngraphs_compact:list[list[dict]]) -> list[dict]:\n",
    "    out = []\n",
    "    for (user, data) in enumerate(ngraphs_compact):\n",
    "\n",
    "        keys = list(data.keys())\n",
    "\n",
    "        # list of mean data of each n-graph across all sets for one user\n",
    "        means = np.array([data[k]['mean'] for k in keys])\n",
    "\n",
    "        # list of median data of each n-graph across all sets for one user\n",
    "        meadians = np.array([data[k]['median'] for k in keys])\n",
    "\n",
    "        # list of std data of each n-graph across all sets for one user\n",
    "        stds = np.array([data[k]['std'] for k in keys])\n",
    "\n",
    "        # calculate average data across all n-graphs\n",
    "        means_mean = round(means.mean())\n",
    "        meadians_mean = round(meadians.mean())\n",
    "        stds_mean = round(stds.mean())\n",
    "\n",
    "        #print(user, \" \", means_mean, \" \", meadians_mean, \" \", stds_mean)\n",
    "\n",
    "        out.append({\n",
    "            \"user\": user,\n",
    "            \"means_mean\": means_mean,\n",
    "            \"meadians_means\": meadians_mean,\n",
    "            \"stds_mean\": stds_mean\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "digraph_avgs = average(compact_digraphs)\n",
    "df = pd.DataFrame.from_records(digraph_avgs)\n",
    "df.to_csv(\"./user_data_digraphs.csv\", index=False)\n",
    "\n",
    "\n",
    "trigraphs_avgs = average(compact_trigraphs)\n",
    "df = pd.DataFrame.from_records(trigraphs_avgs)\n",
    "df.to_csv(\"./user_data_trigraphs.csv\", index=False)\n",
    "\n",
    "\n",
    "fourgraphs_avgs = average(compact_fourgraphs)\n",
    "df = pd.DataFrame.from_records(fourgraphs_avgs)\n",
    "df.to_csv(\"./user_data_fourgraphs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
