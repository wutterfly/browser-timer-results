{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification, Authentication, and Identification of users based on free-text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "minimum_profile_length_r = 10\n",
    "minimum_profile_length_a = 10     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user__  = [0] * 31\n",
    "global user_i__\n",
    "user_i__ = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert raw data to n-graph profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keystrokes_to_digraphs(keystroke_array):\n",
    "    digraphs = []\n",
    "    i = 0    \n",
    "    while i < len(keystroke_array) - 1:\n",
    "        digraphs.append((\n",
    "            str(keystroke_array[i][0]) +\"-\"+ str(keystroke_array[i+1][0]),\n",
    "            np.round((keystroke_array[i+1][1]-keystroke_array[i][1]), 5)\n",
    "            ))\n",
    "        i +=1\n",
    "    return digraphs\n",
    "\n",
    "def keystrokes_to_trigraphs(keystroke_array):\n",
    "    trigraphs = []\n",
    "    i = 0\n",
    "    while i < len(keystroke_array) - 2:   \n",
    "        trigraphs.append((\n",
    "            str(keystroke_array[i][0])+\"-\"+str(keystroke_array[i+1][0]) + \"-\" + str(keystroke_array[i+2][0]), \n",
    "            np.round((keystroke_array[i+2][1]-keystroke_array[i][1]), 5)\n",
    "            ))\n",
    "        i +=1\n",
    "    return trigraphs\n",
    "\n",
    "def keystrokes_to_fourgraphs(keystroke_array):\n",
    "    fourgraphs = []\n",
    "    i = 0\n",
    "    while i < len(keystroke_array) -3:\n",
    "        fourgraphs.append((\n",
    "            str(keystroke_array[i][0]) + \"-\" + str(keystroke_array[i+1][0]) + \"-\" + str(keystroke_array[i+2][0]) + \"-\" + str(keystroke_array[i+3][0]), \n",
    "            np.round((keystroke_array[i+3][1] - keystroke_array[i][1]), 5)\n",
    "        ))\n",
    "        i += 1\n",
    "    return fourgraphs\n",
    "\n",
    "\n",
    "def calculate_mean_for_duplicates(ngraphs):\n",
    "    cleaned_ngraphs = []\n",
    "    processed_keys = []\n",
    "    for key, time in ngraphs:\n",
    "        if key not in processed_keys:\n",
    "            duplicates = [e for e in ngraphs if e[0] == key ]\n",
    "            if len(duplicates) > 1:\n",
    "                processed_keys.append(key)\n",
    "                cleaned_ngraphs.append((key, np.round(np.mean([d[1] for d in duplicates]), 5)))\n",
    "            else :\n",
    "                processed_keys.append(key)\n",
    "                cleaned_ngraphs.append((key,time))\n",
    "    return cleaned_ngraphs\n",
    "\n",
    "def create_user_profile(keystroke_sequence):\n",
    "    digraphs = calculate_mean_for_duplicates(keystrokes_to_digraphs(keystroke_sequence))\n",
    "    trigraphs = calculate_mean_for_duplicates(keystrokes_to_trigraphs(keystroke_sequence))\n",
    "    fourgraphs = calculate_mean_for_duplicates(keystrokes_to_fourgraphs(keystroke_sequence))\n",
    "    return digraphs, trigraphs, fourgraphs\n",
    "\n",
    "\n",
    "def read_file(complete: pd.DataFrame, user: int, set: int) -> list[(str, int)]:\n",
    "    key_codes = complete.loc[(complete['user'] == user) & (complete['set'] == set)]['key'].to_list()\n",
    "    timestamps =complete.loc[(complete['user'] == user) & (complete['set'] == set)]['timestamp'].to_list()\n",
    "\n",
    "    keystrokes = [(str(k), t) for (k,t) in zip(key_codes, timestamps)]\n",
    "\n",
    "    return keystrokes\n",
    "\n",
    "def read_user_data(complete):\n",
    "    users = []\n",
    "    \n",
    "    for user in range(1, 32):\n",
    "        tmp_keystrokes = []\n",
    "        for set in range(1, 16):\n",
    "            f = read_file(complete, user, set)\n",
    "            tmp_keystrokes.append(f)\n",
    "        users.append(tmp_keystrokes)\n",
    "    return users\n",
    "\n",
    "def get_user_profiles(user_data):\n",
    "    user_profiles = []\n",
    "    count = 0\n",
    "    for u_data in user_data:\n",
    "        digraphs = []\n",
    "        trigraphs =[]\n",
    "        fourgraphs = []\n",
    "        for sample in u_data:\n",
    "            tmp_digraphs, tmp_trigraphs, tmp_fourgraphs = create_user_profile(sample)\n",
    "            digraphs.append(dict(tmp_digraphs))\n",
    "            trigraphs.append(dict(tmp_trigraphs))\n",
    "            fourgraphs.append(dict(tmp_fourgraphs))\n",
    "\n",
    "        user_profiles.append({\"digraphs\": digraphs, \"trigraphs\": trigraphs, \"fourgraphs\": fourgraphs})\n",
    "        count += 1\n",
    "    return user_profiles\n",
    "\n",
    "def create_user_profiles(path_to_userdata, filename):\n",
    "    user_data2 = read_user_data(pd.read_csv(path_to_userdata))\n",
    "    user_profiles = get_user_profiles(user_data2)\n",
    "    with open(filename, \"wb\") as fp:\n",
    "        pickle.dump(user_profiles, fp)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for calculating R- and A-distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r_distance(reference_ngraphs, evaluation_ngraphs):\n",
    "\n",
    "    '''\n",
    "    Returns the r(elative)-distance. \n",
    "    The higher the distance, the bigger the difference between profile and sample.\n",
    "    The distance lies between 0 and 1 ([0, 1]).\n",
    "    '''\n",
    "\n",
    "\n",
    "    # number of shared n-graphs\n",
    "    number_of_shared_ngraphs = len(evaluation_ngraphs)\n",
    "\n",
    "    # check that a minimal number of n-graphs are shared\n",
    "    # else maximum distance\n",
    "    if number_of_shared_ngraphs < minimum_profile_length_r:\n",
    "        global user_i__\n",
    "        user__[user_i__] += 1\n",
    "        return 1\n",
    "    \n",
    "    # order refernce(user profile) n-graphs based on n-grpah duration\n",
    "    reference_ordered = list(dict(sorted(reference_ngraphs.items(), key= lambda item: item[1])))\n",
    "   \n",
    "    # order sample n-graphs based on n-grpah duration\n",
    "    evaluation_ordered = list(dict(sorted(evaluation_ngraphs.items(), key= lambda item: item[1])))\n",
    "    \n",
    "    # calculate distances between n-graph positions in reference and evaluation datasets\n",
    "    ordered_distances = [abs(evaluation_ordered.index(ele) - idx) for idx, ele in enumerate(reference_ordered)]\n",
    "    \n",
    "    # calculate maximum degree of disorder\n",
    "    # (if |V| is even) 0> (|V|^2 / 2)\n",
    "    if number_of_shared_ngraphs % 2 == 0:\n",
    "        maximum_disorder = ((number_of_shared_ngraphs * number_of_shared_ngraphs)) / 2\n",
    "    # (if |V| is odd) => (|V|^2 − 1) / 2\n",
    "    else:\n",
    "        maximum_disorder = ((number_of_shared_ngraphs * number_of_shared_ngraphs) - 1) / 2\n",
    "    \n",
    "    \n",
    "    # if there are no shared n-graphs ?\n",
    "    assert len(ordered_distances) == number_of_shared_ngraphs\n",
    "    if len(ordered_distances) == 0:\n",
    "        print(\"WARN: No R distance\")\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        # calculate r-distance\n",
    "        distance = np.sum(ordered_distances) / maximum_disorder\n",
    "        return np.round(distance, 6)\n",
    "\n",
    "def calculate_a_distance(reference_ngraphs, evaluation_ngraphs, threshold):\n",
    "    '''\n",
    "    Returns the a(bsolute)-distance. \n",
    "    The higher the distance, the bigger the difference between profile and sample.\n",
    "    The distance lies between 0 and 1 ([0, 1]).\n",
    "    '''\n",
    "\n",
    "    # number of shared n-graphs\n",
    "    number_of_shared_ngraphs = len(evaluation_ngraphs)\n",
    "\n",
    "    # check that a minimal number of n-graphs are shared\n",
    "    if number_of_shared_ngraphs < minimum_profile_length_a:\n",
    "        global user_i__ \n",
    "        user__[user_i__] += 1\n",
    "        return 1\n",
    "    \n",
    "    similar_ngraphs = 0\n",
    "\n",
    "    # 1 < max(d1, d2)/min(d1, d2) ≤ t\n",
    "    # => similar\n",
    "\n",
    "    # for each n-graph\n",
    "    for n_graph in evaluation_ngraphs:\n",
    "\n",
    "        d1 = reference_ngraphs[n_graph]\n",
    "        d2 = evaluation_ngraphs[n_graph]\n",
    "\n",
    "        # 1 < max(d1, d2)/min(d1, d2) ≤ t\n",
    "        # => similar\n",
    "\n",
    "        # TODO:\n",
    "        # make sure it's > 1\n",
    "        if d2 >= d1:\n",
    "            # shouldn't this be a devision: /  \n",
    "            if (d2 - d1) <= threshold:\n",
    "                similar_ngraphs += 1\n",
    "        else:\n",
    "            # shouldn't this be a devision: / \n",
    "            if (d1 - d2) <= threshold:\n",
    "                similar_ngraphs += 1\n",
    "\n",
    "    # calculate a-distance\n",
    "    # 1 − (number of similar n-graphs between S1 and S2)/(total number of n-graphs shared by S1 and S2)\n",
    "    distance = 1 - (similar_ngraphs / number_of_shared_ngraphs)\n",
    "\n",
    "    return np.round(distance, 6)\n",
    "\n",
    "\n",
    "def calculate_a_distance_alt_(reference_ngraphs, evaluation_ngraphs, threshold):\n",
    "\n",
    "    # number of shared n-graphs\n",
    "    number_of_shared_ngrpahs = len(evaluation_ngraphs)\n",
    "\n",
    "    # check that a minimal number of n-graphs are shared\n",
    "    if number_of_shared_ngrpahs < minimum_profile_length_a:\n",
    "        return 1\n",
    "\n",
    "\n",
    "    similar_ngraphs = 0\n",
    "\n",
    "    # for each n-graph\n",
    "    for n_graph in evaluation_ngraphs:\n",
    "\n",
    "        d1 = reference_ngraphs[n_graph]\n",
    "        d2 = evaluation_ngraphs[n_graph]\n",
    "\n",
    "        # 1 < max(d1, d2)/min(d1, d2) ≤ t\n",
    "\n",
    "\n",
    "        # max(d1, d2) => d2\n",
    "        # min(d1, d2) => d1\n",
    "        if d2 > d1 and d1 != 0:\n",
    "            if (d2 / d1) <= threshold:\n",
    "                similar_ngraphs += 1\n",
    "        # max(d1, d2) => d1\n",
    "        # min(d1, d2) => d2\n",
    "        elif d1 > d2 and d2 != 0:\n",
    "            if (d1 / d2) <= threshold:\n",
    "                similar_ngraphs += 1\n",
    "            \n",
    "    distance = 1 - (similar_ngraphs / number_of_shared_ngrpahs)\n",
    "\n",
    "    return np.round(distance, 6)\n",
    "\n",
    "\n",
    "\n",
    "def get_matching_subsets(ngraphs_a, ngraphs_b):\n",
    "    '''\n",
    "        Returns data for each set for n-graphs that are present in both sets. \n",
    "    '''\n",
    "    # get intersection(shared) of keys \n",
    "    intersection = ngraphs_a.keys() & ngraphs_b.keys()\n",
    "\n",
    "    # only keep n-graphs that are present in both sets\n",
    "    set_a = dict(map(lambda key: (key, ngraphs_a.get(key, None)), intersection))\n",
    "    set_b = dict(map(lambda key: (key, ngraphs_b.get(key, None)), intersection))\n",
    "    return set_a , set_b\n",
    "\n",
    "def get_a_distance(ngraph_profile, ngraph_sample):\n",
    "    '''\n",
    "    Returns the average a-distance between a set of profiles and a sample\n",
    "    '''\n",
    "\n",
    "    # hold distance to each profile\n",
    "    distances = []\n",
    "\n",
    "    # for ach profile: len 14\n",
    "    for profile in ngraph_profile:\n",
    "        # get data sets only containing shared n-graphs\n",
    "        set_a, set_b = get_matching_subsets(profile, ngraph_sample)\n",
    "\n",
    "        # calculate a-distance\n",
    "        distance = calculate_a_distance(set_a, set_b, 1.05)\n",
    "\n",
    "        distances.append(distance)\n",
    "\n",
    "    # return average a distance for each profile\n",
    "    return np.mean(distances)\n",
    "\n",
    "def get_r_distance(ngraph_profile, ngraph_sample):\n",
    "    '''\n",
    "    Returns the average r-distance between a set of profiles and a sample\n",
    "    '''\n",
    "\n",
    "    # hold distance to each profile\n",
    "    distances = []\n",
    "\n",
    "    # for each profile: len 14\n",
    "    for profile in ngraph_profile:\n",
    "        # get data sets only containing shared n-graphs\n",
    "        set_a, set_b = get_matching_subsets(profile, ngraph_sample)\n",
    "\n",
    "        # calculate r-distance\n",
    "        distance = calculate_r_distance(set_a, set_b)\n",
    "\n",
    "        # TODO\n",
    "        # no distance n-graph ordering match exactly ?\n",
    "        # r distance is between [0, 1]\n",
    "        if distance != 99:\n",
    "            distances.append(distance)\n",
    "    \n",
    "    if len(distances) == 0:\n",
    "        return 1\n",
    "    \n",
    "    # calculate average distance\n",
    "    return np.round(np.mean(distances), 5)\n",
    "\n",
    "def get_mean_r_distance(samples_digraphs, samples_trigraps, samples_fourgraphs):\n",
    "    '''\n",
    "        Returns the mean r-distance of a profile.\n",
    "    '''\n",
    "    \n",
    "    # list of all combination for all user samples (except combination of the same sample)\n",
    "    # len: 14*13\n",
    "    distances_digraphs = []\n",
    "    distances_trigraphs = []\n",
    "    distances_fourgraphs = []\n",
    "\n",
    "     # 14 * 13: each combination of digraphs in all samples\n",
    "    for i1, s1 in enumerate(samples_digraphs):\n",
    "        for i2, s2 in enumerate(samples_digraphs):\n",
    "            # exact with each other/same sample\n",
    "            if i1 != i2:\n",
    "                # \n",
    "                set_a, set_b = get_matching_subsets(s1, s2)\n",
    "                distances_digraphs.append(calculate_r_distance(set_a, set_b))\n",
    "\n",
    "    # 14 * 13: each combination of trigraphs in all samples\n",
    "    for i1, s1 in enumerate(samples_trigraps):\n",
    "        for i2, s2 in enumerate(samples_trigraps):\n",
    "            # exact with each other/same sample\n",
    "            if i1 != i2:\n",
    "                set_a, set_b = get_matching_subsets(s1, s2)\n",
    "                distances_trigraphs.append(calculate_r_distance(set_a, set_b))\n",
    "\n",
    "     # 14 * 13: each combination of fourgraphs in all samples\n",
    "    for i1, s1 in enumerate(samples_fourgraphs):\n",
    "        for i2, s2 in enumerate(samples_fourgraphs):\n",
    "            # exact with each other/same sample\n",
    "            if i1 != i2:\n",
    "                set_a, set_b = get_matching_subsets(s1, s2)\n",
    "                distances_fourgraphs.append(calculate_r_distance(set_a, set_b))\n",
    "\n",
    "\n",
    "    # returns average distances for digraphs, trigraphs and fourgraphs\n",
    "    return (np.mean(distances_digraphs) , np.mean(distances_trigraphs), np.mean(distances_fourgraphs))\n",
    "\n",
    "def get_mean_a_distance(samples_digraphs, samples_trigraps, samples_fourgraphs):\n",
    "    '''\n",
    "        Returns the mean a-distance of a profile.\n",
    "    '''\n",
    "\n",
    "    # list of all combination for all user samples (except combination of the same sample)\n",
    "    # len: 14*13\n",
    "    distances_digraphs = []\n",
    "    distances_trigraphs = []\n",
    "    distances_fourgraphs = []\n",
    "\n",
    "    # 14 * 13: each combination of digraphs in all samples\n",
    "    for i1, s1 in enumerate(samples_digraphs):\n",
    "        for i2, s2 in enumerate(samples_digraphs):\n",
    "            # exact with each other/same sample\n",
    "            if i1 != i2:\n",
    "                set_a, set_b = get_matching_subsets(s1, s2)\n",
    "                distances_digraphs.append(calculate_a_distance(set_a, set_b, 1.05))\n",
    "    \n",
    "    # 14 * 13: each combination of trigraphs in all samples\n",
    "    for i1, s1 in enumerate(samples_trigraps):\n",
    "        for i2, s2 in enumerate(samples_trigraps):\n",
    "            # exact with each other/same sample\n",
    "            if i1 != i2:\n",
    "                set_a, set_b = get_matching_subsets(s1, s2)\n",
    "                distances_trigraphs.append(calculate_a_distance(set_a, set_b, 1.05))\n",
    "\n",
    "    # 14 * 13: each combination of fourgraphs in all samples\n",
    "    for i1, s1 in enumerate(samples_fourgraphs):\n",
    "        for i2, s2 in enumerate(samples_fourgraphs):\n",
    "            # exact with each other/same sample\n",
    "            if i1 != i2:\n",
    "                set_a, set_b = get_matching_subsets(s1, s2)\n",
    "                distances_fourgraphs.append(calculate_a_distance(set_a, set_b, 1.05))\n",
    "\n",
    "    # returns average distances for digraphs, trigraphs and fourgraphs\n",
    "    return (np.mean(distances_digraphs) , np.mean(distances_trigraphs), np.mean(distances_fourgraphs))\n",
    "\n",
    "\n",
    "def get_a_distances(user_profile_digraph, user_profile_trigraph, user_profile_fourgraph, sample_digraph, sample_trigraph, sample_fourgraph):\n",
    "    '''\n",
    "        Returns the a2, a3, a4 distance from sample to user profile.\n",
    "    '''\n",
    "    \n",
    "    # calculate a2 distance from user profile to sample\n",
    "    a2 = get_a_distance(user_profile_digraph, sample_digraph)\n",
    "     # calculate a3 distance from user profile to sample\n",
    "    a3 = get_a_distance(user_profile_trigraph, sample_trigraph)\n",
    "     # calculate a4 distance from user profile to sample\n",
    "    a4 = get_a_distance(user_profile_fourgraph, sample_fourgraph)\n",
    "\n",
    "    return (a2, a3, a4)\n",
    "\n",
    "def get_r_distances(user_profile_digraph, user_profile_trigraph, user_profile_fourgraph, sample_digraph, sample_trigraph, sample_fourgraph):\n",
    "    '''\n",
    "        Returns the r2, r3, r4 distance from sample to user profile.\n",
    "    '''\n",
    "    \n",
    "    # calculate r2 distance from user profile to sample\n",
    "    r2 = get_r_distance(user_profile_digraph, sample_digraph)\n",
    "    # calculate r3 distance from user profile to sample\n",
    "    r3 = get_r_distance(user_profile_trigraph, sample_trigraph)\n",
    "    # calculate r4 distance from user profile to sample\n",
    "    r4 = get_r_distance(user_profile_fourgraph, sample_fourgraph)\n",
    "\n",
    "    return (r2, r3, r4)\n",
    "\n",
    "def calculate_distances(user_profile_digraph, user_profile_trigraph, user_profile_fourgraph, sample_digraph, sample_trigraph, sample_fourgraph):\n",
    "    '''\n",
    "        Returns the combination of all distances from sample to user profile.\n",
    "    '''\n",
    "    \n",
    "    # calculate a-distances between user profile and samples\n",
    "    # len: 3 -> (a2, a3, a4)\n",
    "    a = get_a_distances(user_profile_digraph, user_profile_trigraph, user_profile_fourgraph, sample_digraph, sample_trigraph, sample_fourgraph)\n",
    "    \n",
    "    # calulate r-distances between user profile and samples\n",
    "    # # len: 3 -> (r2, r3, r4)\n",
    "    r = get_r_distances(user_profile_digraph, user_profile_trigraph, user_profile_fourgraph, sample_digraph, sample_trigraph, sample_fourgraph)\n",
    "    \n",
    "    # return all distance combination\n",
    "    return {\n",
    "        \"a2\": a[0],\n",
    "        \"a3\": a[1],\n",
    "        \"a4\": a[2],\n",
    "        \"a23\": a[0]+a[1],\n",
    "        \"a24\": a[0]+a[2],\n",
    "        \"a34\": a[1]+a[2],\n",
    "        \"a234\": a[0]+a[1]+a[2],\n",
    "        \"r2\": r[0],\n",
    "        \"r3\": r[1],\n",
    "        \"r4\": r[2],\n",
    "        \"r23\": r[0]+r[1],\n",
    "        \"r24\": r[0]+r[2],\n",
    "        \"r34\": r[1]+r[2],\n",
    "        \"r234\": r[0]+r[1]+r[2],\n",
    "        \"r2_a2\": r[0]+ a[0],\n",
    "        \"r2_a23\": r[0]+a[0]+a[1],\n",
    "        \"r2_a24\": r[0]+a[0]+a[2],\n",
    "        \"r2_a234\": r[0]+a[0]+a[1]+a[2],\n",
    "\n",
    "        \"r23_a2\": r[0]+r[1] + a[0],\n",
    "        \"r23_a23\": r[0]+r[1] + a[0]+a[1],\n",
    "        \"r23_a24\": r[0]+r[1] + a[0]+a[2],\n",
    "        \"r23_a234\": r[0]+r[1] + a[0]+a[1]+a[2],\n",
    "\n",
    "        \"r234_a2\": r[0]+r[1]+r[2] + a[0],\n",
    "        \"r234_a23\": r[0]+r[1]+r[2] +  a[0]+a[1],\n",
    "        \"r234_a24\": r[0]+r[1]+r[2] +  a[0]+a[2],\n",
    "        \"r234_a234\": r[0]+r[1]+r[2] + a[0]+a[1]+a[2]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_user_experiment(user_profiles_training, user_profile_evaluation, user):\n",
    "\n",
    "    ''''''\n",
    "    \n",
    "    # userA = {setA1, setA2, setA3, .., setA15}\n",
    "    # md(userA, sampleX) = [d(setA1, sampleX) + d(setA2, sampleX) +···+ d(setAn, sampleX)]/n\n",
    "    # classify sampleU => min(md(userA, sampleU), md(userB, sampleU), ...)\n",
    "\n",
    "    tp_a2 = 0\n",
    "    tp_a3 = 0\n",
    "    tp_a4 = 0\n",
    "    tp_a23 = 0\n",
    "    tp_a24 = 0\n",
    "    tp_a34 = 0\n",
    "    tp_a234 = 0\n",
    "\n",
    "    tp_r2 = 0\n",
    "    tp_r3 = 0\n",
    "    tp_r4 = 0\n",
    "    tp_r23 = 0\n",
    "    tp_r24 = 0\n",
    "    tp_r34 = 0\n",
    "    tp_r234 = 0\n",
    "\n",
    "    tp_r2_a2 = 0\n",
    "    tp_r2_a23 = 0\n",
    "    tp_r2_a24 = 0\n",
    "    tp_r2_a234 = 0\n",
    "\n",
    "    tp_r23_a2 = 0\n",
    "    tp_r23_a23 = 0\n",
    "    tp_r23_a24 = 0\n",
    "    tp_r23_a234 = 0\n",
    "\n",
    "    tp_r234_a2 = 0\n",
    "    tp_r234_a23 = 0\n",
    "    tp_r234_a24 = 0\n",
    "    tp_r234_a234 = 0\n",
    "\n",
    "    # for each user data set\n",
    "    for j in range(0, 15):\n",
    "        a2_distance = []\n",
    "        a3_distance = []\n",
    "        a4_distance = []\n",
    "        a23_distance = []\n",
    "        a24_distance = []\n",
    "        a34_distance = []\n",
    "        a234_distance = []\n",
    "\n",
    "        r2_distance = [] \n",
    "        r3_distance = []\n",
    "        r4_distance = []\n",
    "        r23_distance = []\n",
    "        r24_distance = []\n",
    "        r34_distance = []\n",
    "        r234_distance = []\n",
    "\n",
    "        r2_a2 = []\n",
    "        r2_a23 = []\n",
    "        r2_a24 = []\n",
    "        r2_a234 = []\n",
    "\n",
    "        r23_a2 = []\n",
    "        r23_a23 = []\n",
    "        r23_a24 = []\n",
    "        r23_a234 = []\n",
    "\n",
    "        r234_a2 = []\n",
    "        r234_a23 = []\n",
    "        r234_a24 = []\n",
    "        r234_a234 = []\n",
    "\n",
    "        # for each user profile: len 31\n",
    "        for u in range(0, len(user_profiles_training)):\n",
    "            global user_i__\n",
    "            user_i__ = u\n",
    "\n",
    "            # lists of n-graphs for each set\n",
    "            # filter out current set: len 15 => len 14\n",
    "            profile_digraphs = [key for i, key in enumerate(user_profiles_training[u][\"digraphs\"]) if not (u == user and i == j) ]#not (u == user and i == j) ]\n",
    "            profile_trigraphs = [key for i, key in enumerate(user_profiles_training[u][\"trigraphs\"]) if not (u == user and i == j) ]#not (u == user and i == j) ]\n",
    "            profile_fourgraphs = [key for i, key in enumerate(user_profiles_training[u][\"fourgraphs\"]) if not (u == user and i == j) ]#not (u == user and i == j) ]\n",
    "            \n",
    "            # assert len(profile_digraphs) == len(profile_trigraphs) == len(profile_fourgraphs) == 14\n",
    "\n",
    "            # get average a-distance combination for each set j to user profile(without set j)\n",
    "            # len 3\n",
    "            a_distances = get_a_distances(\n",
    "                profile_digraphs, # len 14 \n",
    "                profile_trigraphs, # len 14\n",
    "                profile_fourgraphs, # len 14\n",
    "                user_profile_evaluation[user][\"digraphs\"][j],# len 1\n",
    "                user_profile_evaluation[user][\"trigraphs\"][j], # len 1\n",
    "                user_profile_evaluation[user][\"fourgraphs\"][j] # len 1\n",
    "            )\n",
    "\n",
    "            assert len(a_distances) == 3\n",
    "\n",
    "            # store a-distances for user\n",
    "            a2_distance.append(a_distances[0])\n",
    "            a3_distance.append(a_distances[1])\n",
    "            a4_distance.append(a_distances[2])\n",
    "            a23_distance.append(a_distances[0]+a_distances[1])\n",
    "            a24_distance.append(a_distances[0]+a_distances[2])\n",
    "            a34_distance.append(a_distances[1]+a_distances[2])\n",
    "            a234_distance.append(a_distances[0]+a_distances[1]+a_distances[2])\n",
    "\n",
    "            # get average r-distances from each set j to user profiles\n",
    "            r_distances = get_r_distances(\n",
    "                profile_digraphs, \n",
    "                profile_trigraphs, \n",
    "                profile_fourgraphs, \n",
    "                user_profile_evaluation[user][\"digraphs\"][j],\n",
    "                user_profile_evaluation[user][\"trigraphs\"][j],\n",
    "                user_profile_evaluation[user][\"fourgraphs\"][j]\n",
    "            )\n",
    "            \n",
    "            # store a-distances for user     \n",
    "            r2_distance.append(r_distances[0])\n",
    "            r3_distance.append(r_distances[1])\n",
    "            r4_distance.append(r_distances[2])\n",
    "            r23_distance.append(r_distances[0]+r_distances[1])\n",
    "            r24_distance.append(r_distances[0]+r_distances[2])\n",
    "            r34_distance.append(r_distances[1]+r_distances[2])\n",
    "            r234_distance.append(r_distances[0]+r_distances[1]+r_distances[2])\n",
    "\n",
    "            # TODO\n",
    "            # store combinations of r- and a-distances for user\n",
    "            r2_a2.append(r_distances[0]+ a_distances[0])\n",
    "            r2_a23.append(r_distances[0] + a_distances[0] + a_distances[1] )\n",
    "            r2_a24.append(r_distances[0] + a_distances[0] + a_distances[2])\n",
    "            r2_a234.append(r_distances[0] + a_distances[0] + a_distances[1] + a_distances[2])\n",
    "\n",
    "            r23_a2.append(r_distances[0]+r_distances[1] + a_distances[0])\n",
    "            r23_a23.append(r_distances[0]+r_distances[1] + a_distances[0]+a_distances[1])\n",
    "            r23_a24.append(r_distances[0]+r_distances[1] + a_distances[0]+a_distances[2])\n",
    "            r23_a234.append(r_distances[0]+r_distances[1] + a_distances[0]+a_distances[1]+a_distances[2])\n",
    "\n",
    "            r234_a2.append(r_distances[0]+r_distances[1]+r_distances[2] + a_distances[0])\n",
    "            r234_a23.append(r_distances[0]+r_distances[1]+r_distances[2] + a_distances[0]+a_distances[1])\n",
    "            r234_a24.append(r_distances[0]+r_distances[1]+r_distances[2] + a_distances[0]+a_distances[2])\n",
    "            r234_a234.append(r_distances[0]+r_distances[1]+r_distances[2] + a_distances[0]+a_distances[1]+a_distances[2])\n",
    "\n",
    "        # check with combination correctly classified user\n",
    "        if user == np.argmin(np.array(a2_distance)):\n",
    "            tp_a2 += 1\n",
    "        if user == np.argmin(np.array(a3_distance)):\n",
    "            tp_a3 += 1\n",
    "        if user == np.argmin(np.array(a4_distance)):\n",
    "            tp_a4 += 1\n",
    "        if user == np.argmin(np.array(a23_distance)):\n",
    "            tp_a23 += 1\n",
    "        if user == np.argmin(np.array(a24_distance)):\n",
    "            tp_a24 += 1\n",
    "        if user == np.argmin(np.array(a34_distance)):\n",
    "            tp_a34 += 1\n",
    "        if user == np.argmin(np.array(a234_distance)):\n",
    "            tp_a234 += 1\n",
    "        \n",
    "        if user == np.argmin(np.array(r2_distance)):\n",
    "            tp_r2 += 1\n",
    "        if user == np.argmin(np.array(r3_distance)):\n",
    "            tp_r3 += 1\n",
    "        if user == np.argmin(np.array(r4_distance)):\n",
    "            tp_r4 += 1\n",
    "        if user == np.argmin(np.array(r23_distance)):\n",
    "            tp_r23 += 1\n",
    "        if user == np.argmin(np.array(r24_distance)):\n",
    "            tp_r24 += 1\n",
    "        if user == np.argmin(np.array(r34_distance)):\n",
    "            tp_r34 += 1\n",
    "        if user == np.argmin(np.array(r234_distance)):\n",
    "            tp_r234 += 1\n",
    "\n",
    "        if user == np.argmin(np.array(r2_a2)):\n",
    "            tp_r2_a2 += 1\n",
    "        if user == np.argmin(np.array(r2_a23)):\n",
    "            tp_r2_a23 += 1\n",
    "        if user == np.argmin(np.array(r2_a24)):\n",
    "            tp_r2_a24 += 1\n",
    "        if user == np.argmin(np.array(r2_a234)):\n",
    "            tp_r2_a234 += 1\n",
    "\n",
    "        if user == np.argmin(np.array(r23_a2)):\n",
    "            tp_r23_a2 += 1\n",
    "        if user == np.argmin(np.array(r23_a23)):\n",
    "            tp_r23_a23 += 1\n",
    "        if user == np.argmin(np.array(r23_a24)):\n",
    "            tp_r23_a24 += 1\n",
    "        if user == np.argmin(np.array(r23_a234)):\n",
    "            tp_r23_a234 += 1\n",
    "\n",
    "        if user == np.argmin(np.array(r234_a2)):\n",
    "            tp_r234_a2 += 1\n",
    "        if user == np.argmin(np.array(r234_a23)):\n",
    "            tp_r234_a23 += 1\n",
    "        if user == np.argmin(np.array(r234_a24)):\n",
    "            tp_r234_a24 += 1\n",
    "        if user == np.argmin(np.array(r234_a234)):\n",
    "            tp_r234_a234 += 1\n",
    "\n",
    "    return tp_a2, tp_a3, tp_a4, tp_a23, tp_a24, tp_a34, tp_a234, tp_r2, tp_r3, tp_r4, tp_r23, tp_r24, tp_r34, tp_r234, tp_r2_a2, tp_r2_a23, tp_r2_a24, tp_r2_a234, tp_r23_a2, tp_r23_a23, tp_r23_a24, tp_r23_a234, tp_r234_a2, tp_r234_a23, tp_r234_a24, tp_r234_a234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_user_for_authentication(training_user_profiles, testing_user_sample, user_index, profile_index):\n",
    "    # will contains the r234_a23 distance for each user \n",
    "    # based on the training data(training_user_profile) for the test sample(testing_user_sample)\n",
    "    r234_a23 = []\n",
    "\n",
    "    for u in range(0, len(training_user_profiles)): # len should be 31 User\n",
    "        # remove current test data(testing_user sample <- user_index, profile_index) from all training data \n",
    "\n",
    "        # get n-graphs for all sets from user(u), except the current(profile_index) set\n",
    "        # => len 14 -> 15 sets - the current(profile_index)\n",
    "        profile_digraphs = [key for i, key in enumerate(training_user_profiles[u][\"digraphs\"]) if not (user_index == u and profile_index == i)]\n",
    "\n",
    "        profile_trigraphs = [key for i, key in enumerate(training_user_profiles[u][\"trigraphs\"]) if not (user_index == u and profile_index == i) ]\n",
    "        \n",
    "        profile_fourgraphs = [key for i, key in enumerate(training_user_profiles[u][\"fourgraphs\"])  if not (user_index == u and profile_index == i)]\n",
    "\n",
    "        # assert len(profile_digraphs) == len(profile_trigraphs) == len(profile_fourgraphs) == 14\n",
    "\n",
    "\n",
    "        # calculate a- and r-distance, \n",
    "        # based on the users profile(without the test set) for the test set\n",
    "\n",
    "        # len 3 -> (a2, a3, a4)\n",
    "        a_distances = get_a_distances(profile_digraphs, profile_trigraphs, profile_fourgraphs, testing_user_sample[\"digraphs\"], testing_user_sample[\"trigraphs\"], testing_user_sample[\"fourgraphs\"])\n",
    "        # len 3 -> (r2, r3, r4)\n",
    "        r_distances = get_r_distances(profile_digraphs, profile_trigraphs, profile_fourgraphs, testing_user_sample[\"digraphs\"], testing_user_sample[\"trigraphs\"], testing_user_sample[\"fourgraphs\"])\n",
    "        \n",
    "        # TODO\n",
    "        # calc distance:    r2           r3             r4                  a2              a3 \n",
    "        distance = r_distances[0] + r_distances[1] + r_distances[2] + a_distances[0] + a_distances[1]\n",
    "        r234_a23.append(distance)\n",
    "\n",
    "    # returns the index(user) with the minimal distance\n",
    "    return np.argmin(np.array(r234_a23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authentication_test_legal_connection(user_profiles_training, user_profiles_evaluation):\n",
    "    # keep track of results\n",
    "    false_reject_classification = 0\n",
    "    false_reject_distance = 0\n",
    "    attempt = 0\n",
    "\n",
    "    # for each user / userprofile:= (digraphs, trigraphs, fourgraphs)\n",
    "    for index_test_user, test_user in enumerate(user_profiles_evaluation):\n",
    "        global user_i__\n",
    "        user_i__ = index_test_user\n",
    "        \n",
    "        print(\"Start legal attempt user \" + str(index_test_user))\n",
    "        # for each user data set\n",
    "        for sample_test_user in range(0, 15):\n",
    "            # try to authenticate\n",
    "            attempt += 1\n",
    "            # classifiy users based on all user profile training data and this users data\n",
    "            # get the user where the sample(sample_test_user) is closest to all user profiles(user_profiles_training)\n",
    "            classified_user = classify_user_for_authentication(user_profiles_training, {\n",
    "                \"digraphs\": test_user[\"digraphs\"][sample_test_user], \n",
    "                \"trigraphs\": test_user[\"trigraphs\"][sample_test_user], \n",
    "                \"fourgraphs\": test_user[\"fourgraphs\"][sample_test_user]\n",
    "                }, index_test_user, sample_test_user)\n",
    "            \n",
    "            # the user was correctly classified\n",
    "            if classified_user == index_test_user:\n",
    "                # get average a-distances for all combination of user sets, without the current set\n",
    "                m_d_a = get_mean_a_distance(\n",
    "                    [key for i, key in enumerate(test_user[\"digraphs\"]) if i != sample_test_user], \n",
    "                    [key for i, key in enumerate(test_user[\"trigraphs\"]) if i != sample_test_user],\n",
    "                    [key for i, key in enumerate(test_user[\"fourgraphs\"]) if i != sample_test_user]\n",
    "                )\n",
    "                \n",
    "                # get average r-distances for all combination of user sets, without the current set\n",
    "                m_d_r = get_mean_r_distance(\n",
    "                    [key for i, key in enumerate(test_user[\"digraphs\"]) if i != sample_test_user], \n",
    "                    [key for i, key in enumerate(test_user[\"trigraphs\"]) if i != sample_test_user], \n",
    "                    [key for i, key in enumerate(test_user[\"fourgraphs\"]) if i != sample_test_user]\n",
    "                )\n",
    "\n",
    "                # mean r234_a23            r2       r3          r4          a2        a3 \n",
    "                mean_distances_user_A = m_d_r[0] + m_d_r[1] + m_d_r[2] + m_d_a[1] + m_d_a[2]                \n",
    "\n",
    "                # calculate all distance combination between this(test_user) and test sample(test_user)\n",
    "                # training data consist of all samples except current sample(sample_test_user. test_user)\n",
    "                mean_distance_profile_test_user = calculate_distances(\n",
    "                    [key for i, key in enumerate(test_user[\"digraphs\"]) if i != sample_test_user], \n",
    "                    [key for i, key in enumerate(test_user[\"trigraphs\"]) if i != sample_test_user], \n",
    "                    [key for i, key in enumerate(test_user[\"fourgraphs\"]) if i != sample_test_user], \n",
    "                    test_user[\"digraphs\"][sample_test_user],  \n",
    "                    test_user[\"trigraphs\"][sample_test_user], \n",
    "                    test_user[\"fourgraphs\"][sample_test_user]\n",
    "                )\n",
    "\n",
    "                # \n",
    "                for index_user_B, user_B in enumerate(user_profiles_training):\n",
    "                    # if user_B is not current(test_user) user\n",
    "                    if index_user_B != index_test_user:\n",
    "                        # calculate averge distance \n",
    "                        mean_distance_sample_user_B = calculate_distances(\n",
    "                            [key for i, key in enumerate(user_B[\"digraphs\"])], \n",
    "                            [key for i, key in enumerate(user_B[\"trigraphs\"])], \n",
    "                            [key for i, key in enumerate(user_B[\"fourgraphs\"])], \n",
    "                            test_user[\"digraphs\"][sample_test_user], \n",
    "                            test_user[\"trigraphs\"][sample_test_user], \n",
    "                            test_user[\"fourgraphs\"][sample_test_user] \n",
    "                        )\n",
    "\n",
    "                        # check \n",
    "                        if mean_distance_profile_test_user[\"r234_a23\"] >= mean_distances_user_A + (0.5 * (mean_distance_sample_user_B[\"r234_a23\"] - mean_distances_user_A)):\n",
    "                            false_reject_distance += 1\n",
    "                            break\n",
    "                        \n",
    "                        # assert False\n",
    "\n",
    "            # the user was wrongly classified\n",
    "            else:\n",
    "                false_reject_classification += 1\n",
    "\n",
    "    print(\"Attempts: \"+ str(attempt) + \" FR_Classification: \"+ str(false_reject_classification) + \" FR_Distance: \" + str(false_reject_distance))\n",
    "    return (attempt, false_reject_classification+false_reject_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authentication_test_attack(user_profiles_training, user_profile_evaluation):\n",
    "    false_accept = 0\n",
    "    attempts = 0\n",
    "\n",
    "    for index_attack_user, attack_user in enumerate(user_profiles_training[0:1]):\n",
    "        print(\"Start attack on user \" + str(index_attack_user))\n",
    "        attacked_users = [user for i, user in enumerate(user_profile_evaluation) if i != index_attack_user]\n",
    "\n",
    "        for sample_attack in range(0, 15):\n",
    "\n",
    "            for index_attacked_user, attacked_user in enumerate(attacked_users):\n",
    "                attempts += 1\n",
    "\n",
    "                classified_user = classify_user_for_authentication(attacked_users, {\n",
    "                    \"digraphs\": attack_user[\"digraphs\"][sample_attack], \n",
    "                    \"trigraphs\": attack_user[\"trigraphs\"][sample_attack], \n",
    "                    \"fourgraphs\": attack_user[\"fourgraphs\"][sample_attack]\n",
    "                }, -1, -1)\n",
    "\n",
    "                if classified_user == index_attacked_user:\n",
    "                    m_d_a = get_mean_a_distance(\n",
    "                        [key for i, key in enumerate(attacked_user[\"digraphs\"])], \n",
    "                        [key for i, key in enumerate(attacked_user[\"trigraphs\"])], \n",
    "                        [key for i, key in enumerate(attacked_user[\"fourgraphs\"])]\n",
    "                    \n",
    "                    )\n",
    "                    m_d_r = get_mean_r_distance(\n",
    "                        [key for i, key in enumerate(attacked_user[\"digraphs\"])], \n",
    "                        [key for i, key in enumerate(attacked_user[\"trigraphs\"])], \n",
    "                        [key for i, key in enumerate(attacked_user[\"fourgraphs\"])]\n",
    "                    \n",
    "                    )\n",
    "                    mean_distances_user_A = m_d_r[0] + m_d_r[1] + m_d_r[2] + m_d_a[1] + m_d_a[2]  \n",
    "\n",
    "                    mean_distance_profile_test_user = calculate_distances(\n",
    "                        [key for i, key in enumerate(attacked_user[\"digraphs\"])], \n",
    "                        [key for i, key in enumerate(attacked_user[\"trigraphs\"])], \n",
    "                        [key for i, key in enumerate(attacked_user[\"fourgraphs\"])], \n",
    "                        attack_user[\"digraphs\"][sample_attack], \n",
    "                        attack_user[\"trigraphs\"][sample_attack], \n",
    "                        attack_user[\"fourgraphs\"][sample_attack]\n",
    "                    )\n",
    "                 \n",
    "                    for index_user_B, user_B in enumerate(attacked_users):\n",
    "                        if index_user_B != index_attacked_user:\n",
    "                            mean_distance_sample_user_B = calculate_distances(\n",
    "                                [key for i, key in enumerate(user_B[\"digraphs\"])], \n",
    "                                [key for i, key in enumerate(user_B[\"trigraphs\"])], \n",
    "                                [key for i, key in enumerate(user_B[\"fourgraphs\"])], \n",
    "                                attack_user[\"digraphs\"][sample_attack], \n",
    "                                attack_user[\"trigraphs\"][sample_attack], \n",
    "                                attack_user[\"fourgraphs\"][sample_attack]\n",
    "                            )\n",
    "                            \n",
    "                            if mean_distance_profile_test_user[\"r234_a23\"] < mean_distances_user_A + (0.5 * (mean_distance_sample_user_B[\"r234_a23\"] - mean_distances_user_A)):\n",
    "                                false_accept += 1\n",
    "                                \n",
    "                                break\n",
    "            \n",
    "                \n",
    "    return (attempts, false_accept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_dataset(path_to_dataset_training, path_to_dataset_evaluation, filename):\n",
    "    # open training data set\n",
    "    with open(path_to_dataset_training, \"rb\") as fp:\n",
    "        user_profiles_training = pickle.load(fp)\n",
    "\n",
    "    # open eval data set\n",
    "    with open(path_to_dataset_evaluation, \"rb\") as fp:\n",
    "        user_profiles_evaluation = pickle.load(fp)\n",
    "\n",
    "\n",
    "\n",
    "    # remove row 13, 18, 26\n",
    "    filter =  []\n",
    "    user_profiles_training = [j for i, j in enumerate(user_profiles_training) if i not in filter]\n",
    "    user_profiles_evaluation = [j for i, j in enumerate(user_profiles_evaluation) if i not in filter]\n",
    "\n",
    "\n",
    "\n",
    "    classifications = []\n",
    "    print(\"start classfication:\")\n",
    "\n",
    "    # for each user\n",
    "    for user_index in range(len(user_profiles_training)):\n",
    "        print(\"start classification for user \" + str(user_index))\n",
    "        user_i__ = user_index\n",
    "\n",
    "        # classify user\n",
    "        classification = classify_user_experiment(user_profiles_training, user_profiles_evaluation, user_index)\n",
    "        classifications.append(classification)\n",
    "        \n",
    "        # create dataframe\n",
    "        df = pd.DataFrame(classifications, columns=[\n",
    "            'a2','a3','a4','a23','a24','a34', 'a234','r2','r3','r4','r23','r24',\n",
    "            'r34','r234', 'r2_a2', 'r2_a23', 'r2_a24', 'r2_a234', 'r23_a2', \n",
    "            'r23_a23', 'r23_a24', 'r23_a234', 'r234_a2', 'r234_a23', 'r234_a24', 'r234_a234' \n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # get sum of correct classifications\n",
    "        sums = df.sum().to_frame()\n",
    "\n",
    "        # total number of tried classifications\n",
    "        total = (15 * (user_index + 1))\n",
    "\n",
    "        # calculate missclassification as (total - sucessfull classifications)\n",
    "        sums[\"Missclassifications\"] = total - sums.iloc[:,0]\n",
    "\n",
    "        # calculate error rate\n",
    "        sums[\"Error\"] = (sums[\"Missclassifications\"] / total) * 100\n",
    "        \n",
    "        # write results to file\n",
    "        sums.to_csv('./__DATA/'+ filename + '_classification_performance.csv')\n",
    "        df.to_csv('./__DATA/' + filename + '_classification.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_dataset(path_to_dataset_training, path_to_dataset_evaluation, filename):\n",
    "    # open training data set\n",
    "    with open(path_to_dataset_training, \"rb\") as fp:\n",
    "        user_profiles_training = pickle.load(fp)\n",
    "\n",
    "    # open eval data sets\n",
    "    with open(path_to_dataset_evaluation, \"rb\") as fp:\n",
    "        user_profiles_evaluation = pickle.load(fp)\n",
    "\n",
    "    # remove row 13, 18, 26\n",
    "    filter =  []\n",
    "    user_profiles_training = [j for i, j in enumerate(user_profiles_training) if i not in filter]\n",
    "    user_profiles_evaluation = [j for i, j in enumerate(user_profiles_evaluation) if i not in filter]\n",
    "    assert len(user_profiles_training) == 31\n",
    "\n",
    "\n",
    "    # try legitimate auth\n",
    "    legal_attempts = authentication_test_legal_connection(user_profiles_training, user_profiles_evaluation)\n",
    "\n",
    "    # try fraudulent auth\n",
    "    attacks = authentication_test_attack(user_profiles_training, user_profiles_evaluation)\n",
    "    \n",
    "    # write results to file\n",
    "    df = pd.DataFrame(data={\n",
    "        'Type':['False Reject', 'False Accept'], \n",
    "        'Attempts':[legal_attempts[0], attacks[0]], \n",
    "        'Result':[legal_attempts[1], attacks[1]]\n",
    "    })\n",
    "    df.to_csv('./__DATA/' + filename + \"_authentication.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in original data\n",
    "original_set = './../freetext/FreeText-Dataset-31-USERS.csv'\n",
    "original_data_profiles = './__DATA/original_data_profiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "if not os.path.isfile(original_data_profiles):\n",
    "    create_user_profiles(original_set, original_data_profiles)\n",
    "\n",
    "authenticate_dataset(original_data_profiles, original_data_profiles, \"original\")\n",
    "classify_dataset(original_data_profiles, original_data_profiles, \"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user__)\n",
    "\n",
    "\n",
    "with open('counters_3.txt', 'w+') as f:\n",
    "    f.write(\"[\")\n",
    "    for x in user__:\n",
    "        f.write(f'{x},')\n",
    "    f.write(\"]\")\n",
    "\n",
    "\n",
    "print(user__[13]) # 40032\n",
    "print(user__[18]) # 36520\n",
    "print(user__[26]) # 36884\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
